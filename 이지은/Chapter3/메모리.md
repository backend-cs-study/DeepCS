# Chapter3-2. 메모리

## 1) 메모리 계층
<img src="https://velog.velcdn.com/images/ajm0718/post/237f19d7-d9e2-4b14-b8a4-4fd7814532b8/image.png">

① **레지스터**: CPU 안에 있는 작은 메모리. 휘발성, 속도가 가장 빠름, 기억용량이 적다.

② **캐시(L1, L2 캐시)**: 휘발성, 속도 빠름, 기억용량이 적다.

③ **주 기억 장치**: 하드디스크로부터 일정량의 데이터를 복사하여 임시저장하고 필요시마다 CPU에 빠르게 전달 <br>
휘발성, 속도 보통, 기억용량 보통

④ **보조 기억 장치(HDD, SSD)**: 비휘발성, 속도 낮음, 기억용량 높음 

* 계층의 이유: 경제성, 캐시

<br>

### 1️⃣ 캐시
* 데이터를 미리 복사해 놓은 임시저장소
* 빠른 장치와 느린 장치 간 속도 차이에 병목현상 감소 → 데이터 접근 시간 감소, 재계산 시간 절약

> #### 📢 캐싱 계층의 예시
> * 메모리와 CPU 사이의 속도 차이로 인해 그 중간에 레지스터 계층이 캐싱 계층으로 사용
> * 캐시 메모리와 보조 기억 장치 사이에서 주 기억 장치가 보조 기억 장치의 캐싱 계층으로 사용

* 캐싱 계층의 캐시 설정 방법: 데이터에 대한 근거 **`지역성'**
  * **시간지역성**: 최근 사용한 데이터에 다시 접근하려는 특성
  * **공간지역성**: 최근 접근한 데이터를 이루고 있는 공간 또는 가까운 공간에 접근하려는 특성
* `캐시히트` 와 `캐시미스`
  * **캐시 히트**: 캐시에서 원하는 데이터를 찾을 때, 제어장치를 거쳐 가져오게 됨 (빠름)
  * **캐시 미스**: 데이터가 캐시에 없다면 주 메모리로 가서 데이터를 찾아오는 것, 메모리에서 가져오게 됨 (시스템버스 기반으로 가져오기 때문에 느림)
* **캐시 매핑**: 캐시가 히트되기 위해 매핑하는 방법
  * **직접 매핑**: 1:1~10 등으로 매핑, 처리가 빠르지만 충돌 발생
  * **연관 매핑**: 순서를 일치시키지 않고 관련있는 캐시와 메모리 매핑. 충돌이 적지만 모든 블록을 탐색해야기 때문에 속도 느림
  * **집합 연관 매핑**: 순서는 일치시키지만 집합을 두어 저장. 블록화 되어 검색어 효율
* 웹 브라우저의 캐시: 보통 사용자 커스텀 정보, 인증 모듈 관련사항을 웹 브라우저에서 저장하여 추후 서버에 요청할 때 자신을 나타내는 아이덴티티나 중복 요청 방지를 위해 쓰이며 오리진에 종속
  * **쿠키**: 만료 기한이 있는 키-값 저장소
    * some site 옵션을 strict로 설정하지 않을 경우 다음 도메인에서 요청 시 자동 전송
    * 4KB까지 데이터를 저장할 수 있고 만료 기한을 저장할 수 있음 
    * httponly: document.cookie로 쿠키를 볼 수 없게 설정
    * 만료기한: 보통 서버에서 만료기한을 설정함
  * **로컬 스토리지**: 만료기한이 없는 키-값 저장소
    * 5MB까지 저장할 수 있으며 웹 브라우저를 닫아도 유지
    * HTTP5를 지원하지 않는 웹 브라우저에서는 사용할 수 없으며 클라이언트에서만 수정 가능
  * **세션 스토리지**: 만료기한이 없는 키-값 저장소
    * 탭 단위로 세션 스토리지 생성. 탭을 닫을 때 데이터 삭제
    * 5MB까지 저장 가능
    * HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없으면 클라이언트에서만 수정 가능
* 데이터베이스의 캐싱 계층
  * 데이터베이스 시스템을 구축할 때 메인 데이터베이스 위에 레디스 데이터베이스 계층을 캐싱 계층으로 두어 성능 향상
  
<br>

## 2) 메모리 관리
### 1️⃣ 가상 메모리
* 하나의 컴퓨터가 실제로 이용가능한 메모리 자원을 추상화 하여 사용자들에게 매우 큰 메모리를 보이게 만드는 것
* 가상 메모리는 실제 주소와 가상 주소가 매핑되어 있고 프로세스의 주소정보가 들어있는 페이지 테이블로 관리
* 속도 향상을 위해 TLB를 사용한다.

> #### 📢 가상 주소와 실제 주소
> * **가상 주소**: 가상적으로 주어진 주소
> * **실제 주소**: 실제 메모리 상의 주소
> * 메모리 관리 장치(MMU): 가상 주소를 실제 주소로 변환

> #### 📢 TLB
> 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시. 
> 페이지 테이블에 있는 리스트를 보관하며 CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층

<br>

### 2️⃣ 스레싱
* 메모리의 페이지 폴트율이 높은 것 → 컴퓨터의 심각한 저하
* 메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 발생
* 페이지 폴트 발생 → CPU 이용률 감소 → 운영체제가 더 많은 프로세스를 메모리에 올리게 됨 → 반복 발생 시 스레싱 발생
* ✅ 해결방법: 메모리를 늘리거나 HDD 대신 SSD사용, 작업세트, PFF 사용

> ### 📢 스와핑과 페이지 폴트
> * **페이지 폴트**: 프로세스의 주소공간에는 데이터가 존재하지만 실제 RAM에는 존재하지 않는 데이터에 접근 
> * **스와핑**: 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 메모리처럼 불러와 페이지 폴드 예방
> * 페이지 폴트와 스와핑 과정
>   1) 어떤 명령어가 유효한 가상 주소에 접근했으나 해당 페이지가 만약 없다면 트랩이 발생되어 운영체제에 알리게 됨
>   2) 운영체제는 실제 디스크로부터 사용하지 않는 프레임 검색
>   3) 해당 프레임을 실제 메모리에 가져와서 페이지 교체 알고리즘을 기반으로 특정 페이지와 교체 (스와핑)
>   4) 페이지 테이블을 갱신시킨 후 해당 명령어 재실행

> #### 📢 페이지와 프레임
> * 페이지: 가상 메모리를 사용하는 최소 크기 단위
> * 프레임: 실제 메모리를 사용하는 최소 크기 단위

#### ① 작업세트
* 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어 미리 메모리에 로드

#### ② PFF (Page Fault Frequency)
* 페이지 폴트 빈도를 조절하는 방법으로 상한성 하한선을 만듦
* 상한선에 도달ㅇ하면 프레임을 늘리고 하한선에 도달하면 프레임을 줄임

<br>

### 3️⃣ 메모리 할당
* 메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리 할당 크기를 기반으로 할당
* **연속 할당**: 메모리에 연속적으로 공간을 할당
  * **고정 분할 방식**: 메모리를 미리 나누어 관리하여 융툥성이 없고, 내부 단편화 발생
  * **가변 분할 방식**: 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용하여 내부 단편화가 발생하지 않으며 외부 단편화가 발생할 수 있음
    * 최초적합: 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당
    * 최적적합: 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당
    * 최악적합: 프로세스의 크기가 가장 차이가 나는 홀에 할당

> #### 📢 단편화와 홀
> * **내부 단편화**: 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
> * **외부 단편화**: 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상
> * 홀: 할당할 수 있는 비어있는 메모리 공간

* **불연속 할당**: 메모리를 연속적으로 할당하지 않음
  * **페이징**: 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스 할당하여 주소변환이 복잡
  * **세그멘테이션**: 세그먼트 단위로 나누는 방식. 코드와 데이터로 나누거나 코드 내의 작은 함수를 세그먼트로 놓고 나눌 수 있음. 공유 또는 변환에 좋으나 홀 크기가 균일하지 않음
  * **페이지드 세그멘테이션**: 프로그램을 의미 단위인 세그먼트로 나누어 공유 및 보안 강점을 두고 동일한 크기의 페이지 단위로 만드는 것

<br>

### 4️⃣ 페이지 교체 알고리즘
* 스와핑을 발생하는데 페이지 교체 알고리즘에 영향

#### ① 오프라인 알고리즘
* 미래에 참조하는 페이지와 현재에 할당하는 페이지를 바꾸는 알고리즘 (최선, 상한 기준이 됨)

#### ② FIFO (First In First Out)
* 가장 먼저 온 페이지를 교체영역에 가장 먼저 놓는 방법

#### ③ LRU (Least Recently Used)
* 참조가 가장 오래된 페이지를 바꾸는 방법
* 각 페이지 마다 계수기와 스택이 필요
* 해시 테이블과 이중 연결 리스트로 구현
  * 해시 테이블은 이중 연결 리스트에서 빠르게 찾을 수 있도록 사용
  * 이중 연결 리스트는 한정된 메모리를 나타냄

#### ④ NUR (Not Used Recently)
* 0과 1을 가진 비트를 두어 (1은 최근 참조, 0은 참조하지 않음) 시계방향으로 돌면서 0을 찾고 0을 찾는 순간 해당 프로세스를 교체하고 1로 바꿈

#### ⑤ LFU (Least Frequently Used)
* 가장 참조 횟수가 적은 페이지 교체