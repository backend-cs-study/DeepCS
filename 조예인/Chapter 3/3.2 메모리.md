# 3.2 메모리
- CPU는 그저 '메모리'에 올라와 있는 프로그램의 명령어들을 실행할 뿐임

# 3.2.1 메모리 계층
- 레지스터, 캐시, 메모리, 저장장치

✔️ 메모리 계층 <br>
- 레지스터 : CPU 안에 있 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음
- 캐시: L1, L2 캐시를 지칭, 휘발성, 속도 빠름, 기역 용량이 적음. 참고로 L3 캐시도 있음
- 주기억장치 : RAM을 가리킴, 휘발성, 속도 보통, 기역 용량이 보통
- 보조기억장치 : HDD, SSD을 일컬음, 비휘발성, 속도 낮음, 기역 용량 많음
<br><br>
- 램은 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고
  - 이를 필요 시마다 CPU에 빠르게 전달하는 역할
- 계층 위로 올라갈수록 가격은 비싸짐
  - 특징 : 용량은 작아지고 속도는 빨라짐
- 이러한 계층이 있는 이유 : 경제성과 캐시 때문
- ex) 16GB RAM은 8만원이면 삼
  - 하지만 16GM SSD는 훨씬 더 싼 가격에 살 수 있음
    - 이러한 경제성 때문에 계층을 두어 관리함
- 이러한 계층 구조는 일상생활에서 경험 가능
  - 계임을 실행하다 보면 '로딩중'이라는 메시지 나오는 것 볼 수 있음
    - 이는 하드디스크 또는 인터넷에서 데이터를 읽어 RAM으로 전송하는 과정이 아직 끝나지 않음을 의미함

## 캐시(cache)
- 데이터를 미리 복사해 놓는 임시 저장소이자
  - 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
- 이를 통해 데이터를 접근하는 시같이 오래 걸리는 경우를 해결하고
  - 무언가를 다시 계산하는 시간을 절약 가능
- 실제로 메모리와 CPU 사이의 속도 차이가 너무 크기 때문에 그 중간에 레지스터 계층을 둬서 속도 차이를 해결함
  - 캐싱 계층 : 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층
    - ex) 캐시 메모리와 보조기억장치 사이에 있는 주기억장치를 보조기억장치의 캐싱 계층이라고 할 수 있음

### 지역성의 원리
- 캐시 계층을 두는 것 말고 캐시를 직접 설정할 때는 어떻게 해야 할까요?
  - 자주 사용하는 데이터를 기반으로 설정해야 함
    - 근거 : 지역성

#### 시간 지역성(temporal locality)
- 최근 사용한 데이터에 다시 접근하려는 특성을 말함
- ex) for 반복문으로 이루어진 코드 안의 변수 i에 계속해서 접근이 이루어짐
- 여기서 데이터는 변수 i이고 최근에 사용했기 때문에 계속 접근해서 +1을 연이어 하는 것을 볼 수 있음

#### 공간 지역성(spatial locality)
- 최근 접근한 데이터를 일고 있는 공간이나 그 가까운 공간에 접근하는 특성
- 공간을 나타내는 배열 arr의 각 요소들에 i가 할당되며
  - 해당 배열에 연속적으로 접근함
  
## 캐시히트와 캐시미스
- 캐시히트 : 캐시에서 원하는 데이터를 찾음
- 캐시미스 : 해당 데이터가 캐시에 없다면 주메모리로 가서 데이터를 찾아오는 것
- 캐시히트를 하게되면 해당 데이터를 제어장치를 거쳐 가져오게 됨
  - 캐시히트의 경우 위치도 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠름
  - 반면에 캐시미스가 발생되면 메모리에서 가져오게 되는데,
    - 이는 시스템 버스를 기반으로 작동하기 때문에 느림

### 캐시매핑
- 캐시가 히트되기 위해 매핑하는 방법
- CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때를 기반으로 설명함
- 레지스터는 주 메모리에 비하면 굉장히 작고 주 메모리는 굉장히 크기 때문에
  - 작은 레지스터가 캐시 계층으로써 역할을 잘 해주려면 이 매핑을 어떻게 하느냐가 중요함

✔️ 캐시매핑 분류 <br>
- 직접 매핑(directed mapping) : 메모리가 1-100이 있고 캐시가 1-10이 있다면 1:1-10, 2:1-20...
  - 이런 식으로 매핑하는 것. 처리가 빠르지만 충돌 발생이 잦음
- 연관 매핑(associative mapping) : 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑함
  - 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느림
- 집합 연관 매핑(set associative mapping) : 직접 매핑과 연관 매핑을 합쳐 놓은 것
  - 순서는 일치시키지만 집합을 둬서 저장하며 블록화되어 있기 때문에 검색을 좀 더 효율적
  - ex) 메모리가 1-100이 있고 캐시가 1-10이 있다면 캐시 1-5에는 1-50의 데이터를 무작위로 저장시키는 것

### 웹 브라우저의 캐시
- 소프트웨어적인 대표적인 캐시로는 웹 브라우저의 작은 저장소 쿠키, 로컬 스토리지, 세션 스토리지가 있음
- 보통 사용자의 커스텀한 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서
  - 추후 서버에 요청할 때 자신을 나타내는 아이덴티티나 중복 요청 방지를 위해 쓰이며 오리진(origin)에 종속됨

#### 쿠키
- 만료기한이 있는 키-값 저장소
- same site 옵션을 strict로 설정하지 않았을 경우 다른 도메인에서 요청했을 때 자동 전송되며,
  - 4KB까지 데이터를 저장할 수 있고 만료기한을 정할 수 있음
- 쿠키를 설정할 때는 document.cookie로 쿠키를 볼 수 없게 httponly 옵션을 거는 것이 중요하며,
  - 클라이언트 또는 서버에서 만료기한 등을 정할 수 있는데 보통 서버에서 만료기한을 정함

#### 로컬 스토리지
- 만료기한이 없는 키-값 저장소
- 5MB까지 저장할 수 있으며 웹 브라우저를 닫아도 유지됨
- HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없음
  - 클라이언트에서만 수정 가능

#### 세션 스토리지
- 만료기한이 없는 키-값 저장소
- 탭 단위로 세션 스토리지를 생성하며, 탭을 닫을 때 해당 데이터가 삭제됨
- 5MB까지 저장할 수 있으며 
  - HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없음
    - 클라이언트에서만 수정 가능

### 데이터베이스의 캐싱 계층
- 참고 : 데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 '캐싱 계층'으로 둬서 성능을 향상시키기도 함

---
# 3.2.2 메모리 관리
- 운영체제의 대표적인 할 일 중 하나
- 컴퓨터 내의 한정된 메모리를 극한으로 활용해야 하는 것

## 가상 메모리(virtual memory)
- 메모리 관리 기법의 하나
- 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여
  - 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만든느 것을 말함
- 가상 주소(logical address) : 가상적으로 주어진 주소
- 실제 주소(physical address) : 실제 메모리상에 있는 주소
- 가장 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환되며,
  - 이 덕분에 사용자는 실제 주소를 의식할 필요 없이 프로그램 구축 가능
- 가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고
  - 프로세스의 주소 정보가 들어있는 '페이지 테이블'로 관리됨
  - 이때 속도 향상을 위해 TLB 사용

✔️ 용어 <br>
- TLB : 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시
  - 페이지 테이블에 있는 리스트를 보관하며 
    - CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층

### 스와핑(swapping)
- IF 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트 발생
- 이때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옯기고 
  - 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것을 스와핑이라고 함
    - 이를 통해 마치 페이지 폴트가 일어나지 않은 것처럼 만듦

### 페이지 폴트(page fault)
- 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터를 접근했을 경우에 발생

✔️ 과정 <br>
1. 어떤 명령어가 유효한 가상 주소에 접근했으나 해당 페이지가 만약 없다면 트랩이 발생되어 운영체제에 알리게 됨
2. 운영체제는 실제 디스크로부터 사용하지 않은 프레임을 찾음
3. 해당 프레임을 실제 메모리에 가져와서 페이지 교체 알고리즘을 기반으로 특정 페이지와 교체함(이때 스와핑이 일어남)
4. 페이지 테이블을 갱신시킨 후 해당 명령어를 다시 시작

✔️ 용어 <br>
- 페이지(page) : 가상 메모리를 사용하는 최소 크기 단위
- 프레임(frame) : 실제 메모리를 사용하는 최소 크기 단위

## 스레싱(thrashing)
- 메모리의 페이지 폴트율이 높은 것
- 컴퓨터의 심각한 성능 저하 초래
- 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생하는 것
- 페이지 폴트가 일어나면 CPU 이용률이 낮아짐
  - 그렇게 되면 운영체제는 "CPU가 한가한가?"라고 생각하여 가용성을 더 높이기 위해
    - 많은 프로세스를 메모리에 올리게 됨
      - 이와 같은 악순환이 반복되며 스레싱이 일어나게 됨
- 해결 방법 : 메모리를 늘리거나, HDD를 사용한다면 HDD를 SSD로 바꾸는 방법
  - 운영체제에서 해결 방법 : 작업 세트와 PFF

### 작업 세트(working set)
- 프로세스의 과거 사용 이력인 지역성(locality)을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것
- 미리 메모리에 로드하면 탐색에 드는 비용을 줄일 수 있고 스와핑 또한 줄일 수 있음

### PFF(Page Fault Frequency)
- 페이지 폴트 빈도를 조절하는 방법
- 상한선과 하한선을 만드는 방법
- 만약 상한선에 도달한다면 프레임을 늘리고 하한선에 도달한다면 프레임을 줄이는 것

## 메모리 할당
- 메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당함

### 연속 할당
- 메모리에 '연속적으로' 공간을 할당하는 것

#### 고정 분할 방식(fixed partition allocation)
- 메모리를 미리 나누어 관리하는 방식
  - 메모리가 미리 나뉘어 있기 때문에 융통성이 없음
  - 또한 내부 단편화가 발생함

#### 가변 분할 방식(variable partition allocation)
- 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용함
- 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있음

✔️ 가변 분할 방식 종류 <br>
- 최초적합 : 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당
- 최적적합 : 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당
- 최악적합 : 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당

✔️ 용어 <br>
- 내부 단편화(internal fragmentation) 
  - : 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
- 외부 단편화(external fragmentation)
  - : 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상
    - ex) 100MB를 55MB, 45MB로 나눴지만 프로그램의 크기는 70MB일 때 들어가지 못하는 것
- 홀(hole) : 할당할 수 있는 비어 있는 메모리 공간

### 불연속 할당
- 메모리를 연속적으로 할당하지 않는 불연속 할당은
  - 현대 운영체제가 쓰는 방법으로 불연속 할당인 페이징 기법이 있음
    - 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고
    - 프로그램마디 페이지 테이블을 두어 이를 풍해 매모리에 프로그램을 할당하는 것
    - 폐이징 기법 말고도 세그맨테이션, 페이지드 세그멘테이션이 있음

#### 페이징(paging)
- 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당함
- 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해짐

#### 세그멘테이션(segmentation)
- 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식
- 프로세스를 이루는 메모리는 코드 영역. 데이터 영역, 스택 영역, 힙영 역으로 이루어지는데 
- 코드와 데이터로 나누거나 코드 내의 작은 함수를 세그먼트로 놓고 나눌 수도 있음 
- 장점 : 공유와 보안 측면
- 단점 : 홀 크기가 균일하지 않음

#### 페이지드 세그멘테이션(paged segmentation)
- 프로그램을 의미 단위인 세그먼트로 나눠 공유나 보안 측면에 강점을 두고 
- 임의의 길이가 아닌 동일한 크기의 페이지 단위로 나누는 것

## 페이지 교체 알고리즘
- 메모리는 한정되어 있기 때문에 스와핑이 많이 일어남
- 스외핑은 많이 일어나지 않도록 설계되어야 하며 
  - 이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어남

### 오프라인 알고리즘(offline algorithm)
- 먼 미래에 찹조되는 페이지와 현재 할당하는 페 이저를 바꾸는 알고리즘이며, 가장 좋은 방법
- 그러나 미래에 사용되는 프로세스를 우리가 알 수 없음
- 즉, 사용한 수 없는 알고리즘이지만 가장 좋은 알고리즘이기 때문에 
- 다른 알고리즘과의 성능 비교에 대한 상한기준(upper bound)을 제공함

### FIFO(First In First Out)
- 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

### LRU(Least Recently Used)
- 참조가 가장 오래된 페이지를 바꿈
- 문제점 : '오래된' 것을 파악 하기 위헤 각 페이지마다 계수기, 스택을 두어야 함
-  LRU 구현을 프로 그래밍으로 구현할 때는 보통 두 개의 자료 구조로 구현함
  - 해시 테이블과 이중 연결 리스트
  - 헤시 테이블 : 이중 연결 리스트에서 빠르게 찾을 수 있도록 쓰고, 
  - 이중 연결 리스트는 한정된 메모리를 나타냄

#### NUR(Not Used Recently)
- LRU에서 발전한 NUR 알고리즘이 있음
- 일명 clock 알고리즘이라고 하며 먼저 0과 1을 가진 비트를 둠
  - 1은 최근에 참조되었고 0은 참조되지 않음을 의미함
  - 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고, 
    - 해당 부분을 1로 바꾸는 알고리즘

### LFU(Least Frequently Used)
- 가장 참조 횟수가 적은 페이지를 교체
- 즉, 많이 사용되지 않은 것을 교체하는 것

---
## ✅ 기본 질문과 답변



---
## ✅ 심화 질문과 답변
