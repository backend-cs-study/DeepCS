# 3.3 프로세스와 스레드
- 프로세스(process) - 작업 : 컴퓨터에서 실행되고 있는 프로그램
  - CPU 스케줄링의 대상이 되는 작업(task)이라는 용어와 거의 같은 의미로 쓰임
- 스레드 - 흐름 : 프로세스 내 작업의 흐름

✔️ 프로그램과 프로세스  <br>
- HDD/SDD(프로그램 언스턴스화) -> RAM(프로세스)
-> CPU 스케줄러 -> CPU
- 프로그램이 메모리에 올라가면 프로세스가 되는 인스턴스화가 일어나고,
  - 이후 운영체제의 CPU 스케줄러에 따라 CPU가 프로세스를 실행함

# 3.3.1 프로세스와 컴파일 과정
- 프로세스 : 프로그램이 메모리에 올라가 인스턴스화된 것
- ex) 프로그램은 구글 크롬 프로그램(chrome.cxe)과 같은 실행 파일이며, 
  - 이를 두 번 클릭하면 구글 크롬 프로세스로 변환되는 것
- 프로그램을 만드는 과정은 만드는 언어마다 다를 수 있으며 
  - 컴파일 언어인 C 언어 기반의 프로그램을 기준으로 설명하면
  - 컴파일러가 컴파일 과정을 통해 컴퓨터가 이해할 수 있는 기계어로 번역하여 실행할 수 있는 파일을 만들게 됨

## 전처리
- 소스코드의 주석을 제거하고 #include 등 헤더 파일을 병합하여 매크로를 치환함

## 컴파일러
- 오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환함

## 어셈블러
- 어셈블리어는 목적 코드(object code)로 변환됨 
- 이때 확장자는 운영체제마다 다른데 리눅스에서는 .o
- ex) 가영.c라는 파일을 만들었을 때 가영.o라는 파일이 만들어지게 됨

## 링커
- 프로그램 내에 있는 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일을 만듦
- 실행 파일의 확장자는 .exe 또는 .out이라는 확장자를 가짐

### 정적 라이브러리와 동적 라이브러리 
- 라이브러리는 정적 라이브러리와 동적 라이브러리로 나뉨
- 정적 라이브러리  : 프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식으로 라이브러리를 쓰는 방법
  - 장점 : 시스템 환경 등 외부 의존도가 낮음 
  - 단점 : 코드 중복 등 메모리 효율성이 떨어지짐
- 동적 라이브러리 : 프로그램 실행 시 필요할 때만 DLL이라는 함수 정보를 통해 참조하여 라이브러리를 쓰는 방법
  - 장점 : 메모리 효율성
  - 단점 : 외부 의존도가 높아짐

---

# 3.3.2 프로세스의 상태
- 프로세스의 상태는 여러 가지 상태 값을 가짐

## 생성 상태(create) 
- 프로세스가 생성된 상태를 의미하며 fork() 또는 exec() 함수를 통해 생성함
- 이때 PCB가 할당됨

### fork() 
- 부모 프로세스의 주소 공간을 그대로 복사하며, 새로운 자식 프로세스를 생성하는 함수
- 주소 공간만 복사할 뿐이지 부모 프로세스의 비동기 작업 등유 상속하지는 않음

### exec()
- 새롭게 프로세스를 생성하는 함수

## 대기 상태(ready)
- 메모리 공간이 충분하면 메모리를 할당받고 아니면 아닌 상태로 대기하고 있으며
  - CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태

## 대기 중단 상태(ready suspended)
- 메모리 부족으로 일시 중단된 상태

## 실행 상태(running)
- CPU 소유권과 메모리를 할당받고 인스트럭션을 수행 중인 상태를 의미함
- 이를 CPU burst가 일어났다고도 표현함

## 중단 상태(blocked)
- 어떤 이벤트가 발생한 이후 기다리며 프로세스가 차단된 상태
- I/O 디바이스에 의한 인터럽트로 이런 현상이 많이 발생하기도 함
- ex) 프린트 인쇄 버튼을 눌렸을 때 프로세스가 잡깐 멈춘 듯합 때

## 일시 중단 상태(bloacked suspended)
- 대기 중단과 유사함
- 중단된 상태에서 프로세스가 실행되려고 했지만 메모리 부족으로 일시 중단된 상태

## 종료 상태(erminated)
- 메모리와 CPU 소유권을 모두 놓고 가는 상태
- 종료는 자연스럽게 종료되는 것도 있지만 
  - 부모 프로세스가 자식 프로세스를 강제시키는 비자 발적 종료(abort)로 종료되는 것도 있음
  - 자식 프로세스에 할당된 자원의 한계치를 넘어서거나 부모 프로세스가 종료되거나 사용자가 process.kill 등 여러 명령어로 프로세스를 종료할 때 발생함

---

### 3.3.3 프로세스의 메모리 구조
- 운영체제는 프로세스에 적절한 메모리를 할당하는데 다음 구조를 기반으로 할당함
  
✔️ 프로세스의 메모리 구조 <br>
- 동적 영역 
  - 스택 
  - 힙
- 정적 영역
  - 데이터 영역(B5S segment)
  - 코드 영역 (Data segment)

- 위에서부터 스택(stack). 힙(heap). 데이터 영역(BSS segment. Data segment), 코드 영역(code segment)으로 나눠짐
- 스택은 위 주소부터 할당되고 힙은 아래 주소부터 합당됨

## 스택과 힙
- 스택과 힙은 동적 할당이 되며, 동적 할당은 런타임 단계에서 메모리를 할당받는 것을 말함
  - 스택은 지역 변수, 매개변수, 실행되는 함수에 의해 늘어들거나 줄어드는 메모리 영역
  - 함수가 호출될 때마다 호출될 때의 환경 등 특정 정보가 스택에 계속해서 저장됨
- 또한, 재귀 함수가 호출된다고 했을 때 새로운 스택 프레임이 매번 사용되기 때문에 
  - 함수 내의 변수 집합이 해당 함수의 다른 인스턴스 변수를 방해하지 않음
- 힙은 동적으로 할당되는 변수들을 담음
  - malloc(). free() 함수를 풍해 관리할 수 있으며 동적으로 관리되는 자료 구조의 경우 힙 영역을 사용함
    - ex) vector :  내부적으로 힙 영역을 사용함

## 데이터 영역과 코드 영역
- 이 영역은 정적 할당되는 영역 
  - 정적 할당은 컴파일 단계에서 메모리문 할당하는 것을 말함 
  - 데이터 영역은 BSS segment와 Data segment, code/text segment로 나뉘어서 저장됨
- BSS segment : 전역 변수 또는 static. const로 선언되어 있고 
  - 0으로 초기화 또는 초기화가 어떠한 값으로도 되어 있지 않은 변수들이 메모리 영역에 할당됨 
- Data segment : 전역 변수 또는 static, const로 선언되어 있고 
  - 0이 아닌 값으로 초기화된 변수가 이 메모리 영역에 할당됨
- code segment는 프로그램의 코드가 들어감

---

# 3.3.4 PCB(Proces Control Block)
- 운영체제에서 프로세스에 대한 메타데이터를 저장한 '데이터를 말함
  - 프로세스 제어 불록이라고도 함  
    - 프로세스가 생성되면 운영체제는 해당 PCB를 생성함
- 프로그램이 실행되면 프로세스가 생성되고 프로세스 주소 값들에 앞서 설명한 스택, 힙 등의 구조를 기반으로 메모리가 할당됨 
  - 그리고 이 프로셰스의 메타데이터들이 PCB에 저장되어 관리됨 
    - 이는 프로세스의 중요한 정보를 포함하고 있기 때문에 일반 사용자가 접근하지 못하도록 커널 스택의 가장 앞부분에서 관리됨

✔️ 용어 <br>
- 메타데이터 : 데이터에 관한 구조화된 데이터이자 데이터를 설명하는 작은 데이터
  - 대량의 정보 가운데에서 찾고 있는 정보를 효율적으로 찾아내서 이용하기 위해 일정한 규책에 따각 콘텐츠에 대해 부여되는 데아터

## PCB의구조
- PCB는 프로세스 스케줄링 상태, 프로셰스 ID 둥의 다음과 같은 정보로 이루어짐
- 프로셰스 스케즐링 상태 : '준비, '일시중단" 등 프로세스가 CPU에 대한 소유권을 얻은 이후의 상태
- 프로셰스ID : 프로세스 ID, 해당 프로세스의 자식 프로세스 ID
- 프로세스 권한 : 컴퓨터 자원 또는 I/O 디바이스에 대한 권한 정보
- 프로그램 카운터: 프로셰스에서 실행해야 할 다음 명령어의 주소에 대한 포인터
- CPU 레지스터 : 프로세스를 실행하기 위해 저장해야 할 레지스터에 대한 정보
- CPU 스케줄링 정보 : CPU 스케줄러에 의해 중단된 시간 등예 대한 정보
- 계정 정보 : 프로세스 실행에 사용된 CPU 사용량, 실행한 유저의 정보
- I/O 상태정보 : 프로세스에 할당된 I/O 디바이스 목록

## 컨텍스트 스위칭(context switching)
- 앞서 설명한 PCB를 기반으로 프로세스의 상태를 저장하고 로드시키는 과정을 말함 
  - 한 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해 발생함 
  - 컴퓨터는 많은 프로그램을 동시에 실행하는 것처럼 보이지만 어떠한 시점에서 실행되고 있는 프로세스는 단 한 개이며, 
    - 많은 프로세스가 동시에 구동되는 것처럼 보이는 것은 다른 프로세스와의 컨텍스트 스위칭이 아주 빠른 속도로 실행되기 때문
- 참고로 사실 현대 컴퓨터는 멀티코어의 CPU를 가지기 때문에 
  - 한 시점에 한 개의 프로그램이라는 설명은 플린 설명
    - 하지만 컨텍스트 스위칭을 선명한 때는 싱글코어를 기준으로 설명함

✔️ 컨텍스트 스위칭 <br>
- 한 개의 프로세스 A가 실행하다 멈추고, 프로세스 A의 PCB를 저장하고 다시 프로세스 B를 로드하여 실행함 
- 그리고 다시 프로세스 B의 PCB를 저장하고 프로세스 A의 PCB를 로드함  
- 컨텍스트 스위칭이 일어날 때 앞의 그림처럼 유휴 시간(idle time)이 발생하는 것을 불 수 있음  
- 이뿐만 아니라 이 컨텍스트 스위칭에 드는 비용이 더 있음 - 바로 캐시미스

### 비용: 캐시미스
- 컨텍스트 스위칭이 일어날 때 프로세스가 가지고 있는 메모리 주소가 그대로 있으면 
  - 잘못된 주소 변환이 생기므로 캐시클리어 과정을 겪게 되고 이 때문에 캐시미스가 발생합

### 스레드에서의 컨텍스트 스위칭
- 참고로 이 컨텍스트 스위칭은 스레드에서도 일어남
  - 스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에 스레드 컨텍스트 스위칭의 경우 비용이 더 적고 시간도 더 적게 걸림

---

# 3.3.5 멀티프로세싱
- 여러 개의 '프로세스', 즉 멀티프로세스를 통해 동시에 두가지 이상의일 을 수행할 수 있는 것을 말함 
  - 이를 통해 하나 이상의 일을 병렬로 처리할 수 있으며 
    - 강점 : 특정 프로세스의 메모리. 프로세스 중 일부에 문제가 발생되더라도 다른 프로세스를 이용해서 처리할 수 있으므로 신뢰성이 높음
      - 참고로 멀티프로세싱은 하드웨어 관점에서 봤을 때 여러 개의 프로세서로 작업을 처리하는 것을 의미하기도 함 
      - 이 책에서는 멀티스레딩과 멀티프로세싱을 비교하고 있고, 
        - 그 다음으로 멀티프로세스 구조를 가진 브라우저를 예시로 들고 있기 때문에 
          - 소프트웨어 관점에서 멀티프로세싱을 설명함

## 웹 브라우저
- 멀티프로세스 구조를 가지고 있으며 다음과 같음

✔️  웹 브라우저의 멀티프로세스 구조 <br>
- 브라우저 프로세스(앞뒤로 가기 주소 표시줄 네크워크 통신 등을 담당합니다.)
- 렌터러 프로세스(보이는 모든 것을 그립니다.)
- 플러그인 프로세스(플러그인을 제어합니다.)
- GPU 프로세스(GPU 작업을 담당합니다.)

- 브라우저 프로세스 : 주소 표시줄, 북마크 막대, 뒤로 가기 버튼, 앞으로 가기 버튼 등을 담당하며 
  - 네트워크 요청이나 파일 접근 같은 권한을 담당함
- 렌더러 프로세스 : 웹 사이트가 '보이는'부분의 모든 것을 제어함
- 플러그인 프로세스: 웹 사이트에서 사용하는 플러그인을 제어함
- GPU 프로세스 : GPU를 이용해서 화면을 그리는 부분을 제어함
  
## IPC(Inter Process Communication)
- 멀티프로세스는 IPC가 가능하며 IPC는 프로세스끼리 데 이터를 주고받고 공유 데이터를 관리하는 메커니즘을 뜻함 
- ex) 클라이언트는 데이터를 요청하고 서버는 클라이언트 요청에 응답하는 것
- IPC의 종류 : 공유 메모리, 파일, 소켓, 익명 파이프, 명명 파이프, 메시지 큐
  - 이들은 모두 메모리가 완전히 공유되는 스레드보다는 속도가 떨어짐
    
### 공유 메모리(shared memory)
- 여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 
  - 프로세스가 서로 통신할 수 있도록 공유 메모리를 생성해서 통신하는 것
- 기본적으로는 각 프로세스의 메모리를 다른 프로세스가 접근할 수 없지만 
  - 공유 메모리를 통해 여러 프로세스가 하나의 메모리를 공유할 수 있음 
    - IPC 방식 중 어떠한 매개체를 통해 데이터를 주고받는 것이 아닌 메모리 자체를 공유하기 때문에 
    - 불필요한 데이터 복사의 오버헤드가 발생하지 않아 가장 빠르며 
      - 같은 메모리 영역을 여러 프로세스가 공유하기 때문에 동기화가 필요함
- 참고로 하드웨어 관점에서 공유 메모리는 CPU가 접근할 수 있는 큰 랜덤 접근 메모리인 RAM을 가리키기도 함

### 파일
- 디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터를 말함 
  - 이를 기반으로 프로세스간 통신을 함

### 소켓
- 동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 
  - 네트워크 인터페이스를 통해 전송하는 데이터를 의미하며 TCP와 UDP가 있음

### 익명 파이프(unnamed pipe)
- 프로세스 간에 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고받으며, 
  - 단방향 방식의 읽기 전용, 쓰기 전용 파이프를 만들어서 작동하는 방식을 말함
- 이는 부모, 자식 프로세스 간에만 사용할 수 있으며 다른 네트워크상에서는 사용이 불가능함

### 명명된 파이프(named pipe)
- 파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 양방향 파이프를 말함 
  - 클라이언트/서버 통신을 위한 별도의 파이프를 제공하며, 여러 파이프를 동시에 사용할 수 있음 
    - 컴퓨터의 프로세스끼리 또는 다른 네트워크상의 컴퓨터와도 통신을 할 수 있음
- 보통 서버용 파이프와 클라이언트용 파이프로 구분해서 작동하며 
  - 하나의 인스턴스를 열거나 여러 개의 인스턴스를 기반으로 통신함

### 메시지큐
- 메시지를 큐(queue) 데이터 구조 형태로 관리하는 것을 의미함 
  - 이는 커널의 전역변수 형태 등 커널에서 전역적으로 관리되며 
    - 장점 : 다른 IPC 방식에 비해서 사용 방법이 매우 직관적이고 간단하며 
      - 다른 코드의 수정 없이 단지 몇 줄의 코드를 추가시켜 간단하게 메시지 큐에 접근할 수 있음
- 공유 메모리를 통해 IPC를 구현할 때 쓰기 및 읽기 빈도가 높으면 동기화 때문에 
  - 기능을 구현하는 것이 매우 복잡해지는데, 이때 대안으로 메시지 큐를 사용하기도 함

---

# 3.3.6 스레드와 멀티스레딩

## 스레드
- 프로세스의 실행 가능한 가장 작은 단위 
  - 프로세스는 여러 스레드를 가질 수 있음
-코드, 데이터, 스택, 힙을 각각 생성하는 프로세스와는 달리 
  - 스레드는 코드, 데이터, 힙은 스레드끼리 서로 공유함 
  - 그 외의 영역은 각각 생성됨

## 멀티스레딩
- 프로세스 내 작업을 여러 개의 스레드, 멀티스레드로 처리하는 기법
  - 스레드끼리 서로 자원을 공유하기 때문에 효율성이 높음 
  - ex) 웹 요청을 처리할 때 새 프로세스를 생성하는 대신 
    - 스레드를 사용하는 웹 서버의 경우 휠씬 적은 리소스를 소비하며,
      - 한 스레드가 중단(blocked)되어도 다른 스레드는 실행(running) 상태일 수 있기 때문에 
        - 중단되지 않은 빠른 처리가 가능함 
        - 또한 동시성에도 큰 장점이 있음
    - 하지만 한 스레드에 문제가 생기면 다른 스레드에도 영향을 끼쳐 
      - 스레드로 이루어져 있는 프로세스에 영향을 줄 수 있는 단점이 있음

✔️ 용어 <br>
- 동시성 : 서로 독립적인 작업들을 작은 단위로 나누고 동시에 실행되는 것처럼 보여주는 것

✔️ 웹 브라우저의 렌더러 프로세스를 이루는 스레드 <br>
- 멀티스레드의 예로는 웹 브라우저의 렌더러 프로세스를 에로 들 수 있음
- 메인 스레드(일당백!)
- 컴포지터 스레드(레이어를 합성해!)
- 워커 스레드(조수입니다)
- 레스터 스레드(화면을 픽셀로 변환하지!)
- 이 프로세스 내에는 메인 스레드, 워커 스레드, 컴포지터 스레드, 레스터 스레드가 존재함

---

# 3.3.7 공유 자원(shared resource)과 임계 영역
- 공유 자원 : 시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 
  - 모니터, 프린터. 메모리. 파일, 데이터 등의 자원이나 변수 등을 의미함 
- 경쟁 상태(race condition) : 이 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황
  - 동시에 접근을 시도할 때 접근의 타이밍이나 순서 등이 결괏값에 영향을 줄 수 있는 상태
- ex) 종선코인 100개
  - 프로세스 A와 프로세스 B가 동시에 접근하여 타이밍이 서로 꼬여 정상 결괏값은 300인데 200이 출력됨
  
## 임계 영역(critical section)
- 둘 이상의 프로세스, 스레드가 공유 자원에 접근할 때 
  - 순서 등의 이유로 결과가 달라지는 코드 영역을 말함 
- 임계 영역을 해결하기 위한 방법은 크게 뮤텍스. 세마포어, 모니터 세 가지가 있으며,
  - 이 방법 모두 상호 배제. 한정 대기, 융통성이란 조건을 만족함 
    - 이 방법에 토대가 되는 메커니즘은 잠금(lock)임 
    - ex) 임계 영역을 화장실이라고 가정하면 
      - 화장실에 A라는 사람이 들어간 다음 문을 잠금
      - 그리고 다음 사람이 이를 기다리다 A가 나오면 화장실을 쓰는 방법임

✔️ 용어 <br>
- 상호 배제(mutual exclusion) : 한 프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없음
- 한정 대기(bounded waiting) : 특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안 됨
- 융통성(progress) : 만약 어떠한 프로세스도 임계 영역을 사용하지 않는다면 
  - 임계 영역 외부의 어떠한 프로세스도 들어갈 수 있으며 이 때 프로세스끼리 서로 방해하지 않음
  
### 뮤텍스(mutex)
- 프로세스나 스레드가 공유 자원을 lock()을 통해 잠금 설정하고 
  - 사용한 후에는 unlock()을 통해 잠금 해제하는 객체
- 잠금이 설정되면 다른 프로세스나 스레드는 잠긴 코드 영역에 접근할 수 없고 해제는 그와 반대
- 또한 뮤텍스는 잠금 또는 잠금 해제라는 상태만을 가짐

### 세마포어(semaphore)
- 일반화된 뮤텍스
- 간단한 정수 값과 두 가지 함수 wait(P 함수라고도 함) 및 signal(V 함수라고도 함)로 공유 자원에 대한 접근을 처리함 
- wait()는 자신의 차례가 올 때까지 기다리는 합수이며. signal()은 다음 프로세스로 순서를 넘겨주는 합수
- 프로세스나 스레드가 공유 자원에 접근하면 세마포어에서 wait() 작업을 수행하고 
  - 프로세스나 스레드가 공유 자원을 해제하면 세마포어에서 signal() 작업을 수행함 
  - 세마포어에는 조건 변수가 없고 프로세스나 스레드가 세마포어 값을 수정할 때 
    - 다른 프로세스나 스레드는 동시에 세마포어 값을 수정할 수 없음

#### 바이너리 세마포어
- 0과 1의 두 가지 값만 가질 수 있는 세마포어
- 구현의 유사성으로 인해 뮤텍스는 바이너리 세마포어라고 할 수 있지만 
- 엄밀히 말하면 뮤텍스는 잠금을 기반으로 상호배제가 일어나는 '잠금 메커니즘'이고, 
- 세마포어는 신호를 기반으로 상호 배제가 일어나는 '신호 메커니즘'
- 신호 메커니즘은 휴대폰에서 노래를 듣다가 친구로부터 전화가 오면 노래가 중지되고 
  - 통화 처리 작업에 관한 인터페이스가 등장하는 것을 상상하면 됨

#### 카운팅 세마포어
- 여러 개의 값을 가질 있는 세마포어이며, 여러 자원에 대한 접근을 제어하는 데 사용됨

### 모니터
- 들 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 
  - 공유 자원을 숨기고 해당 접근에 대해 인터페이스만 제공함
- 모니터는 모니터큐를 통해 공유 자원에 대한 작업들을 순차적으로 처리함
- 모니터는 세마포어보다 구현하기 쉬우며 모니터에서 상호 배제는 자동인 반면에,
- 세마포어에서는 상호 배제를 명시적으로 구현해야 하는 차이점이 있음

---

# 3.3.8 교착 상태(deadlock)
- 두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태
- ex) 프로세스 A가 프로세스 B의 어떤 자원을 요청할 때 
  - 프로세스 B도 프로세스 A가 점유하고 있는 자원을 요청하는 것

## 교착 상태의 원인
- 상호배제 : 한 프로세스가 자원을 독점하고 있으며 다른 프로세스들은 접근이 불가능함
- 점유대기 : 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태
- 비선점 : 다른 프로세스의 자원을 강제적으로 가져올 수 없음
- 환형 대기 : 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 요구하는 등
  - 서로가 서로의 자원을 요구하는 상황을 말함

## 교착상태의 해결 방법
1. 자원을 할당할 때 애초에 조건이 성립되지 않도록 설계함
2. 교착 상태 가능성이 없을 때만 자원 할당되며, 프로세스당 요청할 자원들의 최대치를 응해 자원 할당 가능 여부를 파악하는 '은행원 알고리즘' 사용
3. 교착 상태가 발생하면 사이클이 있는지 찾아보고 이에 관련된 프로세스를 한 개씩 지움
4. 교착상태는 매우 드물게 일어나기 때문에 이를 처리하는 비용이 더 커서 교착 상태가 발생하면 사용자가 작업을 종료함 현대 운영체제는 이 방법을 채택함. ex) 프로세스를 실행시키다 '응답없음'이라고 뜰 때가있죠? 교착상태가 발생한 경우에 이와 같은 경우가 발생하기도 함

✔️ 용어 <br>
- 은행원 알고리즘 : 총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 또는 불안정 상태로 나누고
  - 안정 상태로 가도록 자원을 할당하는 알고리즘

---
## ✅ 기본 질문과 답변

### Q1. 프로세스와 스레드의 차이는 무엇인가요?

- **답변:**
- 프로세스는 실행 중인 프로그램 단위로, 독립적인 메모리 공간을 갖습니다.
- 반면 스레드는 프로세스 내에서 실행 흐름 단위로, 같은 메모리 공간(코드, 힙, 데이터 영역)을 공유하고 스택만 따로 사용합니다.
- 즉, 프로세스는 자원 격리가 강하지만 스레드는 자원을 공유하므로 문맥 전환 비용이 더 적고, 동시성에 유리합니다.

### Q2. 스레드 기반 서버와 프로세스 기반 서버의 차이점은?

- **답변:**
- 스레드 기반 서버는 하나의 프로세스 내에서 여러 스레드가 클라이언트 요청을 처리하므로 메모리 사용이 적고 성능이 좋습니다.
- 반면 프로세스 기반은 요청마다 독립적인 프로세스를 생성하므로 안정성은 높지만 자원 소모가 큽니다.
- Java 기반 웹 서버는 멀티스레드 구조로, WAS 내에서 여러 요청을 스레드로 처리합니다.

### Q3. 컨텍스트 스위칭이란 무엇이며, 비용이 발생하는 이유는?

- **답변:**
- 컨텍스트 스위칭은 실행 중인 프로세스의 상태(PCB)를 저장하고, 다른 프로세스의 상태를 로드해 CPU를 전환하는 과정입니다.
- 이 과정에서 캐시 미스가 발생할 수 있고, 스케줄링과 메모리 복원 등의 오버헤드가 있어 성능 저하의 원인이 될 수 있습니다.

### Q4. 뮤텍스와 세마포어의 차이점은?

- **답변:**
- 뮤텍스는 오직 하나의 스레드만 접근 가능한 잠금 방식입니다.
- 세마포어는 wait/signal 개념을 기반으로 여러 접근을 제어할 수 있으며, 카운팅 기능을 가집니다.
- 즉, 뮤텍스는 상호 배제 전용이고, 세마포어는 동기화 목적도 함께 사용됩니다.

### Q5. 프로세스 간 통신(IPC)의 종류는 무엇이 있고, 각각의 장단점은?

**답변:**

* **공유 메모리**: 속도가 가장 빠르나 동기화가 필요함
* **소켓**: 네트워크 기반 통신 가능, 유연성 높음
* **파이프(익명/명명)**: 단방향 또는 양방향 통신, 사용 제한 존재
* **메시지 큐**: 구현이 간단하고 안정적이나 상대적으로 느림

### Q6. 멀티스레딩의 장점과 단점은?

- **답변:** 
- 장점은 자원 공유로 인한 메모리 효율과 빠른 응답성입니다. 
- 단점은 하나의 스레드 오류가 전체 프로세스에 영향을 줄 수 있고, 동기화 이슈가 발생할 수 있다는 점입니다.

### Q7. 동시성 문제(race condition)를 방지하는 방법은?

- **답변:**
- 임계 영역을 뮤텍스, 세마포어, 모니터 등으로 보호하고, 상호 배제·한정 대기·진행 조건을 만족하도록 설계합니다.
- Java에서는 `synchronized`, `Lock`, `ReentrantLock`, `volatile` 등을 활용합니다.

### Q8. 프로세스의 메모리 구조에 대해 설명해주세요.

- **답변:**
프로세스는 코드 영역, 데이터 영역(Data, BSS), 힙, 스택으로 나뉩니다.

* **코드 영역**: 실행할 명령어
* **데이터 영역**: 전역변수 등
* **힙**: 동적 할당 메모리
* **스택**: 함수 호출 시 생성되는 임시 메모리

힙과 스택은 런타임 중 동적으로 변하며, 충돌 방지를 위해 반대 방향으로 자라납니다.

### Q9. 교착 상태란 무엇이고 이를 해결하기 위한 방법은?

**답변:**
여러 프로세스가 서로가 가진 자원을 기다리며 무한 대기하는 상태입니다.
해결 방법으로는:

1. 자원 순서를 고정하여 요청 (lock 순서 고정)
2. 타임아웃 설정
3. 교착 상태 감지 후 프로세스 중단
   운영체제에서는 보통 감지가 아닌 회피 전략을 택하거나 사용자에게 강제 종료를 요구합니다.

---
## ✅ 심화 질문과 답변

### 🔸 Q1. 웹 서버를 운영할 때, 스레드 개수를 무작정 늘리면 어떤 문제가 발생할 수 있나요?

- **답변:**
- 스레드를 과도하게 늘리면 CPU 컨텍스트 스위칭 비용과 메모리 사용량이 급증해 성능이 오히려 저하될 수 있습니다.
- 특히 GC가 자주 일어나거나 스레드 간 lock 충돌이 많아지는 경우 병목이 생깁니다.
- 따라서 시스템 자원(CPU 코어 수, 메모리 크기)에 맞춰 thread pool 크기를 조정해야 하며, Java 기반에서는 `Executors.newFixedThreadPool()` 등의 적절한 제한이 중요합니다.

### 🔸 Q2. 백엔드 서버에서 GC와 스와핑이 동시에 발생하면 어떤 현상이 생기고, 어떻게 대응해야 할까요?

- **답변:**
- GC는 메모리 접근이 많은 작업입니다. 이때 OS 스와핑(디스크로 메모리 일부를 밀어냄)이 발생하면 GC 시간이 길어져 전체 응답 지연이 생깁니다.
- 심할 경우 서버가 zombie 상태가 될 수 있습니다.

* 대응 방법:
* GC 로그 분석과 heap dump를 통한 원인 파악
* G1GC나 ZGC 도입
* 힙 크기 제한
* `vm.swappiness` 값을 낮추어 스와핑 억제
* 수평 확장으로 부하 분산



### 🔸 Q3. Redis는 메모리 기반 캐시인데, 왜 eviction 정책이 필요하고 어떤 전략이 있나요?

**답변:**
Redis는 메모리에 데이터를 저장하므로 용량이 한정되어 있습니다.
메모리가 가득 차면 더 이상 저장할 수 없기 때문에 낡은 데이터를 버리는 eviction(퇴출) 정책이 필요합니다.

대표 전략:

* **noeviction**: 더 이상 저장 불가 (오류 발생)
* **volatile-lru**: TTL이 설정된 키 중 가장 오래 사용되지 않은 것 제거
* **allkeys-lru**: 모든 키 중 가장 오래 사용되지 않은 것 제거
* **volatile-ttl**: TTL이 가장 짧게 남은 키 제거

백엔드에서는 TTL 설정과 캐시 적중률 모니터링이 중요합니다.

### 🔸 Q4. 공유 자원에 동시에 접근하는 웹 서버 코드가 있다고 가정해보세요. 동시성 문제를 어떻게 예방하겠습니까?

- **답변:**
- 공유 자원에 대한 동시 접근은 race condition을 일으킬 수 있어 결과가 예측 불가능해집니다.
- Java에서는 `synchronized`, `ReentrantLock`, `AtomicInteger` 등의 동기화 도구를 사용해 임계 구역을 보호할 수 있습니다.
- 스프링 환경이라면 Redis 기반 분산 락(Redisson 등)도 활용 가능합니다.
- 단, 락을 과도하게 사용하면 성능 저하가 있으므로 주의가 필요합니다.

### 🔸 Q5. WAS(예: Tomcat)에서 메모리 누수나 OOM이 발생했을 때 어떻게 분석하고 해결할 수 있나요?

**답변:**

1. GC 로그와 Heap Dump를 수집합니다 (`jmap`, `jstat`, `jvisualvm`)
2. 누수 의심 객체나 미해제 리스너, 컬렉션 참조 확인
3. 반복 요청에서 생성되고 해제되지 않는 객체가 있는지 추적
4. 애플리케이션 캐시 누적, thread pool 미정리 등 확인
5. 문제 객체가 확인되면 코드 수정 후 힙 크기와 GC 전략도 재조정합니다



### 🔸 Q6. 프로세스 간 통신 IPC 중 가장 빠른 방식은 무엇이며, 언제 사용할 수 있나요?

- **답변:**
- **공유 메모리(shared memory)** 방식이 가장 빠릅니다.
- 프로세스 간 복사 없이 같은 메모리 블록을 참조하기 때문에 성능상 유리하지만, 동기화 이슈를 직접 해결해야 합니다 (mutex 등).
- 고속 데이터 전달이 필요하고 같은 머신 내에서 동작하는 마이크로서비스 간 통신 등에 활용될 수 있습니다.

### 🔸 Q7. 스레드 컨텍스트 스위칭 비용이 높은 이유는 무엇인가요?

**답변:**
스레드는 코드/데이터/힙을 공유하지만 스택과 레지스터는 독립적입니다.
따라서 전환 시:

* 레지스터 상태 저장/복구
* 캐시 미스 발생 (이전 스레드의 캐시 날아감)
* 커널 모드 진입 비용
  등이 추가되어 오버헤드가 생깁니다.
  이를 줄이기 위해 스레드 수를 제한하거나, 비동기 프로그래밍을 사용하는 경우도 많습니다.