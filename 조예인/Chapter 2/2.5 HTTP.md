# 2.5 HTTP
- 기본적으로 HTTP는 앞서 설명한 전송 계층 위에 있는 애플리케이션 계층으로서 웹 서비스 통신에 사용됨

# 2.5.1 HTTP/1.0
- HTTP/1.0은 기본적으로 한 연결당 하나의 요청을 처리하도록 설계됨
- 이는 RTT 증가를 불러오게 됨

## RTT 증가
✔️ 설명 <br>
- 서버로부터 파일을 가져올 때마다 TCP의 3-웨이 핸드셰이크를 계속해서 열어야 하기 떄문에
- RTT가 증가하는 단점 발생

✔️ 용어 <br>
- RTT : 패킷이 목적지에 도달하고 나서 다시 출발지로 돌아오기까지 걸리는 시간이며 패킷 왕복 시간

## RTT의 증가를 해결하기 위한 방법
- 매번 연결할 때마다 RTT가 증가하니
- 서버에 부담이 많이 가고
- 사용자 응답시간이 길어짐
- 해결 방법 : 이미지 스플리팅, 코드 압축, 이미지 Base64 인코딩 사용

### 이미지 스플리팅
- 하나의 이미지를 기반으로 background-position을 통해 2개의 이미지 설정

### 코드 압축
- 코드를 압축해서 개행 문자, 빈칸을 없애서 코드의 크기 최소화 하는 방법

### 이미지 Base64 인코딩
- 이미지 파일을 64진법으로 이루어진 문자열로 인코딩하는 방법
- 장점 : 서버와의 연결을 열고 이미지에 대해 서버에 HTTP 요청을 할 필요가 없음
- 단점 : Base64 문자열로 변환할 경우 37% 정도 크기가 더 커짐

✔️ 용어 <br>
- 인코딩 : 정보의 형태나 형식을 표준화, 보안, 처리 속도 향상, 저장 공간 절약 등을 위해 다른 형태나 형식으로 변환하는 처리 방식


# 2.5.2 HTTP/1.1
- HTTP/1.0에서 발전한 것
- 매번 TCP 연결을 하는 것이 아니라 한 번 TCP 초기화를 한 이후에 keep-alive라는 옵션으로 여러 개의 파일을 송수신할 수 있게 바뀜
- HTTP/1.0에서도 keep-alive가 있었지만 표준화 X
- HTTP/1.1부터 표준화가 되어 기본 옵션으로 설정됨
- 한 번 TCP 3-웨이 핸드셰크가 발생하면 그다음부터 발생하지 않음
- 단점 : 문서 안에 포함된 다수의 리소스(이미지, 동영상, css 파일, js 파일 등)를 처리하려면 요청할 리소스 개수에 비례해서 대기 시간 길어짐

## HOL Blocking(Head Of Ling Blocking)
- 네트워크에서 같은 큐에 있는 패킷이 그 첫 번쨰 패킷에 의해 지연될 때 발생하는 성능 저하 현상
- ex) image.jpg가 느리게 받아진다면 그 뒤에 있는 것들이 대기하게 되며 다운로드가 지연되는 상태가 됨

## 무거운 헤더 구조
- HTTP/1.1의 헤더에는 쿠키 등 많은 메타데이터가 들어 있고 압축이 되지 않음 무거웠음

---
# 2.5.3 HTTP/1.2
- SPDY 프로토콜에서 파상된 HTTP/1.x보다 지연 시간을 줄이고 응답 시간을 더 빠르게 할 수 있으며
- 멀티플렉싱, 헤더 압축, 서버 푸시, 요청의 우선순위 처리를 지원하는 프로토콜

## 멀티플렉싱
- 여러 개의 스트림을 사용하여 송수신한다는 것
- 이를 통해 특정 스트림의 패킷이 손실되었다고 하더라도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡하게 동작 가능

✔️ 용어 <br>
- 스트림(stream) : 시간이 지남에 따라 사용할 수 있게 되는 일련의 데이터 요소를 가리키는 데이터 흐름

- 병렬적인 스트림들을 통해 데이터 서빙
- 스트림 내의 데이터들도 쪼개져 있음
- 애플리케이션에서 받아온 메시지를 독립된 프레임으로 조각내어 서로 송수신한 이후 다시 조립하며 데이터를 주고받음
- 이를 통해 단일 연결을 사용하여 병렬로 여러 요청을 받을 수 있고 응답을 줄 수 있음
- 이렇게 되면 HTTP/1.x에서 발생하는 문제인 HOL Blocking 해결 가능

## 헤더 압축
- HTTP/1.x에는 크기가 큰 헤더라는 문제가 있음
- 이를 HTTP/2에서는 헤더 압축을 써서 해결함, 허프만 코딩 압축 알고리즘 사용하는 HPACK 압축 형식을 가짐

### 허프만 코딩(huffman coding)
- 문자열을 문자 단위로 쪼개 빈도수를 세어 빈도가 높은 정보는 적은 비트 수를 사용하여 표현하고,
- 빈도가 낮은 정보는 비트 수를 많이 사용하여 표현해서
- 전체 데이터의 표현에 필요한 비트양을 줄이는 원리

## 서버 푸시
- HTTP/1.1에서는 클라이언트가 서버에 요청을 해야 파일 다운로드 가능
- HTTP/2는 클라이언트 요청 없이 서버가 바로 리소스 푸시 가능
- ex) html을 읽으면서 그 안에 들어 있던 css 파일을 서버에서 푸시ㅏ여 클라이어트에 먼저 줄 수 있음

---
# 2.5.4 HTTPS
- HTTP/2는 HTTPS 위에서 동작함
- 애플리케이션 계층과 전송 계층 사이에 신뢰 계층인 SSL/TLS 계층을 넣은 신뢰할 수 있는 HTTP 요청
- '통신을 암호화'

## SSL/TLS(Secure Socket Layer / Transport Layer Security Protocol)
- 전송 계층에서 보안을 제공하는 프로토콜
- 클라이언트와 서버가 통신할 때 SSL/TLS를 통해 제3자가 메시지를 도청하거나 변조하지 못하도록 함
- 네트워크 상의 인터셉터(공격자가 서버인 척하며 사용자 정보를 가로채는) 방지 가능
- 보안 세션을 기반으로 데이터를 암호하며 보안 세션이 만들어질 때 인증 메커니즘, 키 교환 암호화 알고리즙, 해싱 알고리즘이 사용됨

### 보안 세션
- 보안이 시작되고 끝나는 동안 유지되는 세션
- SSL/TLS는 핸드셰이크를 통해 보안 세션을 생성하고 이를 기반으로 상태 정보 등을 공유함

✔️ 용어 <br>
- 세션 : 운영체제가 어떠한 사용자로부터 자신의 자산 이용을 허락하는 일정한 기간을 뜻한다.
  - 즉, 사용자는 일정 시간 동안 응용 프로그램, 자원 등을 사용할 수 있다.

✔️ TLS의 핸드셰이크 <br>
- 클라이언트와 서버와 키를 공유하고 
  - 이를 기반으로 인증, 인증 확인 등의 작업이 일어나는 
  - 단 한 번의 1-RTT가 생긴 후 데이터를 송수신하는 것을 볼 수 있음
- 클라이언트에서 사이퍼 슈트를 서버에 전달하면
  - 서버는 받은 사이퍼 슈트의 암호화 알고리즘 리스트를 제공할 수 있는지 확인함
  - 제공할 수 있다면 서버에서 클라이언트로 인증서를 보내는 인증 매커니즘이 시작되고 이후 해싱 알고리즘 등으로 암호화된 데이터의 송수신이 시작됨

#### 사이퍼 슈트
- 프로토콜, AEAD 사이퍼 모드, 해싱 알고리즘이 나열된 규약

#### AEAD 사이퍼 모드(Authenticated Encryption with Associated Data)
- 데이터 암호화 알고리즘
- ex) AES_128_GCM : 128비트의 키를 사용하는 표준 블록 암호화 기술과 병렬 계산에 용이한 암호화 알고리즘 GCM이 결합된 알고리즘

### 인증 메커니즘
- CA(Certificate Authorities)에서 발급한 인증서를 기반으로 이루어짐
- CS에서 발급한 인증서는 안전한 연결을 시작하는 데 있어 필요한 '공개키'를 클라이언트에 제공하고
  - 사용자가 접속한 '서버가 신뢰'할 수 있는 서버임을 보장함
- 인증서는 서비스 정보, 공개키, 지문, 디지털 서명 등으로 이루어짐
- 참고로 CA는 아무 기업이나 할 수 있는 것이 아니고
  - 신뢰성이 엄격하게 공인된 기업들만 참여 가능

#### CA 발급 과정
- 자신의 서비스가 CA 인증서를 발급받으려면 자신의 사이트 정보와 공개키를 CA에 제출해야 함
- 이후 CA는 공개키를 해시한 값인 지문을 사용하는 CA의 비밀키 등을 기반으로 CA 인증서를 발급함

✔️ 용어 <br>
- 개인키 : 비밀키라고도 하며, 개인이 소유하고 있는 키이자 반드시 자신만이 소유해야 하는 키
- 공개키 : 공개되어 있는 키

### 암호화 알고리즘
- 키 교환 암호화 알고리즘으로는
  - 대수곡선 기반의 ECDHE 또는 DHE를 사용함
  - 둘 다 디피-헬만 방식을 근간으로 만들어짐

#### 디피-헬만 키 교환 암호호 알고리즘(Diffie-Hellman key exchange)
- 암호키를 교환하는 하나의 방법
- y = gxmodp
- g,x,p를 안다면 y는 구하기 쉽지만 g,y,p만 안다면 x를 구하기는 어렵다는 원리에 기반한 알고리즘
- 처음에 공개 값을 공유하고 각자의 비밀 값과 혼합한 후 혼합 값을 공유함
  - 그 다음 각자의 비밀 값과 또 혼합함
  - 그 이후에 공통의 암호키인 PSK(Pre-Shared Key)가 생성됨
- 이렇게 클라이언트와 서버 모두 개인키와 공개키를 생성하고,
  - 서로에게 공개키를 보내고 공개키와 개인키를 결합하여 PSK가 생성된다면,
  - 악의적인 공격자가 개인키 또는 공개키를 가지고도 PSK가 없기 때문에 아무것도 할 수 없음
  - 이를 통해 키를 암호화 가능

### 해싱 알고리즘
- 데이터를 추정하기 힘든 더 작고, 섞여 있는 조각으로 만드는 알고리즘
- SSL/TLS는 해싱 알고리즘
  - SHA-256 & SHA-384 알고리즘을 사용

#### SHA-256 알고리즘
- 해시 함수의 결괏값이 256비트인 알고리즘
  - 비트 코인을 비롯한 많은 블록체인 시스템에서도 사용
- 해싱을 해야 할 메시지에 1을 추가하는 등 전처리를 하고
  - 전처리된 메시지를 기반으로 해시를 변환함
- 도무지 무슨 뜻인지 알아들을 수 없는 문자열로 변환됨

✔️ 용어 <br>
- 해시 : 다양한 길이를 가진 데이터를 고정된 길이를 가진 데이터로 매핑한 값
- 해싱 : 임의의 데이터를 해시로 바꿔주는 일이며 해시 함수가 이를 담당
- 해시 함수 : 임의의 데이터를 입력으로 받아 일정한 길이의 데이터로 바꿔주는 함수

✔️ 0-RTT <br>
- TLS 1.3은 사용자가 이전에 방문한 사이트로 다시 방문한다면
  - SSL/TLS에서 보안세션을 만들 때 걸리는 통신을 하지 않아도 됨

## SEO에도 도움이 되는 HTTPS
- SEO(Search Engine Optimization) : 검색엔진 최적화
  - 사용자들이 구글, 네이버 같은 검색엔진으로 웹 사이트를 검색했을 때 그 결과를 페이지 상단에 노출시켜
  - 많은 사람이 볼 수 있도록 최적화하는 방법
  
### 캐노니컬 설정
- 사이트 link에 캐노니컬 설정

### 메타 설정
- html 파일의 가장 윗부분인 메타를 잘 설정해야 함

### 페이지 속도 개선
- 사이트의 속도는 빨라야 함
- 구글의 PageSpeedInsights로 가서 자신의 서비스에 대한 리포팅을 주기적으로 받으며 관리해야 함

### 사이트맵 관리(sitemap.xml)
- 사이트맵을 정기적으로 관리하는 것은 필수
- 사이트맵 제너레이터를 사용하거나 직접 코드를 만들어 구축해도 됨

## HTTPS 구축 방법
1. 직접 CA에서 구매한 인증키를 기반으로 HTTPS 서비스를 구축
2. 서버 앞단의 HTTPS를 제공하는 로드밸런서 두기
3. 서버 앞단에 HTTPS를 제공하는 CDN을 두기

---
# 2.5.3 HTTP/3
- HTTP/1.1 및 HTTP/2와 함께 World Wide Web에서 정보를 교환하는데 사용되는 HTTP의 세 번 쨰 버전
  - TCP 위에서 돌아가는 HTTP/2와는 달리
  - HTTP/3은 QUIC이라는 계층 위에서 돌아가며,
  - TCP 기반이 아닌 UDP 기반으로 돌아감
- 또한, HTTP/2에서 장점이었던 멀티플렉싱을 가지고 있으며
  - 장점 : 초기 연결 설정 시 지연 시간 감소

## 초기 연결 설정 시 지연 시간 감소
- QUIC는 TCP를 사용하지 않기 때문에
  - 통신을 시작할 때 번거로운 3-웨이 핸드셰이크 과정을 거치지 않아도 됨
- QUIC는 첫 연결 설정에 1-RTT만 소요됨
  - 클라이언트가 서버에 어떤 신호를 한 번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신 시작 가능
- 참고로 QUIC는 순방향 오류 수정 메커니즘(FEC, Forword Error Correction)이 적용
  - 전송한 패킷이 손실되었다면 수신 측에서 에러를 검축하고 수정하는 방식
  - 열악한 네트워크 환경에서도 낮은 패킷 손실률을 자랑

---
## ✅ 기본 질문과 답변

🔹 **Q1. HTTP/1.0의 주요 단점은 무엇인가요?**
- HTTP/1.0은 한 번의 TCP 연결에 하나의 요청만 처리할 수 있기 때문에, 
- 매 리소스 요청마다 새로운 TCP 연결을 해야 합니다.
- 이로 인해 \*\*RTT(Round Trip Time)\*\*가 반복적으로 발생하며, 성능이 저하됩니다.
- 웹 페이지에 이미지, CSS, JS 등 다양한 리소스가 포함되면 이 단점이 더욱 두드러집니다.

**📌 꼬리 질문:** RTT 문제를 해결하기 위한 방법에는 어떤 것이 있나요?
- 이미지 스플리팅, 코드 압축, Base64 인코딩 등을 통해 
- HTTP 요청 횟수를 줄이거나 데이터 전송량을 줄여 성능을 개선할 수 있습니다.

<br>

🔹 **Q2. HTTP/1.1에서 keep-alive는 어떤 역할을 하나요?**
- HTTP/1.1부터 기본적으로 **keep-alive** 연결이 적용되어, 
- 하나의 TCP 연결로 여러 요청을 처리할 수 있습니다.
- 이를 통해 3-way handshake를 반복하지 않아도 되므로 RTT가 줄고, 성능이 향상됩니다.

**📌 꼬리 질문:** 그럼에도 HTTP/1.1에서 발생할 수 있는 성능 저하 원인은 무엇인가요?
- HOL(Head-of-Line) Blocking입니다. 
- 선행 요청의 지연이 뒤따르는 요청 전체를 지연시키는 문제로, 병렬성 확보가 어렵습니다.

<br>

🔹 **Q3. HTTP/2에서 멀티플렉싱은 무엇이며, 어떤 장점을 제공하나요?**
- 멀티플렉싱은 하나의 TCP 연결에서 여러 요청과 응답을 **병렬로 동시에 처리**할 수 있는 기능입니다.
- 각 요청은 독립된 **스트림**으로 분리되어 처리되기 때문에, 
- 하나의 리소스 지연이 전체 성능에 영향을 미치지 않습니다.

**📌 꼬리 질문:** 멀티플렉싱 외에 HTTP/2에서 성능 개선을 위해 도입된 기술은?
- 헤더 압축(HPACK), 서버 푸시, 요청 우선순위 기능 등이 있습니다.

<br>

🔹 **Q4. HTTP/2에서 사용하는 헤더 압축 방식은 무엇이며, 어떤 원리로 작동하나요?**
- HTTP/2는 **HPACK**이라는 압축 방식을 사용하여 헤더를 줄입니다.
- 이는 **허프만 코딩**을 사용하여 자주 등장하는 헤더 값을 짧은 비트로 변환합니다.
- 이를 통해 네트워크 대역폭을 절감하고 응답 시간을 줄일 수 있습니다.

<br>

🔹 **Q5. HTTP/3는 기존 HTTP/2와 비교해 어떤 차이점이 있나요?**
- HTTP/3는 TCP가 아닌 **UDP 기반**의 전송 프로토콜인 **QUIC** 위에서 동작합니다.
- TCP의 핸드셰이크 과정을 생략하고 1-RTT로 연결을 시작하므로 **지연 시간 감소**가 핵심 장점입니다.
- 또한, HTTP/2와 마찬가지로 멀티플렉싱을 지원하지만, HOL Blocking 문제도 더 잘 해결됩니다.

**📌 꼬리 질문:** QUIC는 패킷 손실에 어떻게 대응하나요?
-  QUIC는 **FEC(Forward Error Correction)** 기법을 사용해 수신 측에서 오류를 복구할 수 있도록 설계되어 있습니다.

<br>

🔹 **Q6. HTTPS는 HTTP에 무엇이 추가된 형태인가요?**
- HTTPS는 HTTP 위에 **SSL/TLS 계층**을 추가한 프로토콜로, 
- 통신을 암호화하여 **도청과 변조를 방지**합니다.
- 웹 서버와 클라이언트 사이에 **인증**, **암호화**, **데이터 무결성 보장**이 가능해지며, 
- 이는 TLS 핸드셰이크 과정을 통해 이루어집니다.

**📌 꼬리 질문:** HTTPS에서 TLS 핸드셰이크란 무엇인가요?
- 클라이언트와 서버가 서로를 인증하고 **공통의 암호화 키**를 설정하는 절차입니다.
- 사이퍼 슈트 선택, 인증서 교환, 키 생성 등을 포함합니다.

<br>

🔹 **Q7. TLS에서 사용하는 주요 보안 기술에는 어떤 것이 있나요?**
* **키 교환**: ECDHE, DHE 같은 디피-헬만 기반 알고리즘
* **인증서 발급**: 신뢰 가능한 CA가 서버 인증서 발급
* **암호화 알고리즘**: AES\_128\_GCM 등
* **해싱 알고리즘**: SHA-256, SHA-384
  이런 기술들이 조합된 **사이퍼 슈트**를 통해 보안이 구성됩니다.

<br>

🔹 **Q8. SEO와 HTTPS의 관계는 무엇인가요?**
- Google은 **HTTPS를 사용하는 사이트를 더 신뢰할 수 있다고 판단**하고, 검색 결과 상위에 노출시킵니다.
- 또한 사이트 속도, 메타 설정, 사이트맵 정리 등과 함께 HTTPS는 \*\*검색엔진 최적화(SEO)\*\*에 중요한 요소입니다.

<br>

🔹 **Q9. HTTP/2와 HTTP/3의 멀티플렉싱 차이점은 무엇인가요?**
- HTTP/2의 멀티플렉싱은 TCP 기반이라 여전히 TCP의 HOL Blocking 영향을 받을 수 있습니다.
- 반면 HTTP/3는 **UDP 기반의 QUIC 프로토콜**을 사용하여 스트림 단위 독립성을 높이고 HOL Blocking을 완전히 제거할 수 있습니다.

---
## ✅ 심화 질문과 답변
🔸 Q1. HTTP/1.1의 Keep-Alive가 성능 개선에 어떤 기여를 하나요?

- HTTP/1.0은 요청마다 TCP 연결을 새로 맺어야 했기 때문에, 
- 매번 3-way handshake와 RTT 비용이 발생했습니다.
- HTTP/1.1의 Keep-Alive는 하나의 TCP 연결을 유지하며 여러 요청을 처리할 수 있게 하여 연결 오버헤드를 줄이고 응답 속도를 개선했습니다. 
- 백엔드 서버 입장에선 커넥션 수가 감소해 부하가 줄고, 처리량이 증가합니다.

<br>

🔸 Q2. HTTP/2에서 멀티플렉싱은 어떻게 동작하고 백엔드에 어떤 영향을 주나요?

- HTTP/2의 멀티플렉싱은 하나의 TCP 연결 안에서 여러 스트림을 병렬로 처리합니다. 
- 각 요청은 프레임 단위로 분할되어 전송되며, 순서와 관계없이 독립적으로 응답할 수 있습니다.
- 백엔드 서버는 큐에 병목 없이 다수 요청을 효율적으로 처리할 수 있지만, 
- 구현 시 스트림 처리 로직의 동시성과 응답 순서를 명확히 고려해야 합니다.

<br>

🔸 Q3. HTTP/2의 Server Push는 어떤 상황에서 유리하고 주의점은?

- Server Push는 클라이언트 요청이 없어도 서버가 관련 리소스를 미리 전송할 수 있어, 
- 초기 로딩 시간을 줄이는 데 유리합니다.
- 단, 리소스 중복 푸시로 대역폭 낭비나 캐싱 오류가 발생할 수 있으므로, 
- 백엔드 서버는 푸시 대상 리소스를 전략적으로 선별해야 합니다.

<br>

🔸 Q4. HTTP/3가 지연 시간 감소에 어떻게 기여하고, 백엔드 구성에 미치는 영향은?

- HTTP/3는 TCP 대신 UDP 기반 QUIC 프로토콜 위에서 동작합니다.
- QUIC는 1-RTT 핸드셰이크, 패킷 손실에 독립적인 스트림 처리 등으로 초기 연결 지연을 크게 줄입니다.
- 백엔드 서버는 HTTP/3를 지원하기 위해 NGINX 또는 Envoy와 같은 프록시 서버에서 QUIC을 설정해야 하고, 
- UDP 기반 트래픽 처리를 고려해야 합니다.

<br>

🔸 Q5. TLS 핸드셰이크에서 성능 병목이 되는 원인은? 백엔드 대응은?

- TLS 핸드셰이크는 공개키 암호화와 인증서 검증이 포함돼 초기 연결에 시간이 소요됩니다. 
- 특히 다수의 HTTPS 연결이 발생하는 경우 CPU 사용량 증가와 응답 지연이 발생할 수 있습니다.
- 백엔드에서는 TLS 세션 재사용(Session Resumption)이나 TLS 1.3의 0-RTT 기능을 활용해 성능을 개선할 수 있습니다. 
- 로드밸런서가 SSL 오프로딩(SSL 처리 분산)을 담당하도록 구성하는 것도 효과적입니다.

<br>

🔸 Q6. HTTPS 환경에서 클라이언트 IP 추적이 어려운 이유와 해결책은?

- HTTPS로 암호화된 요청은 중간 장비(프록시, 로드밸런서)가 내용을 파악할 수 없어, 
- 실제 클라이언트 IP 추적이 어려울 수 있습니다.
- 이를 해결하기 위해 백엔드 서버에서는 `X-Forwarded-For` 헤더나 `X-Real-IP` 헤더를 사용해 로깅해야 하며, 
- 이를 신뢰할 수 있는 경로에서만 사용해야 합니다.

<br>

🔸 Q7. HTTP/1.1과 HTTP/2를 모두 지원하는 서버를 운영할 때 주의할 점은?

- 클라이언트가 HTTP/1.1인지 HTTP/2인지를 서버가 판단해 올바른 프로토콜로 응답해야 합니다. 
- TLS의 ALPN 확장을 사용하면 서버는 클라이언트와 협상 후 적절한 프로토콜을 선택할 수 있습니다.
- 백엔드 개발자는 서로 다른 요청 처리 방식(단일 vs 멀티 스트림)에 맞는 응답 구조, 캐싱 정책, 오류 처리 로직을 구성해야 합니다.

---
## ✅ 심화 질문과 답변(예시 포함)

🔹 Q1. HTTP/1.0에서 RTT가 늘어나는 이유는 무엇인가요?

- HTTP/1.0은 요청마다 TCP 연결을 새로 맺습니다.
- 즉, 매 리소스마다 3-Way Handshake → 요청 → 응답 → 연결 종료 절차를 반복하므로 
- RTT(Round Trip Time)가 누적되어 지연이 발생합니다.

💡 예시 그림

```
클라이언트 --- SYN ---> 서버  
클라이언트 <--- SYN-ACK --- 서버  
클라이언트 --- ACK ---> 서버  
클라이언트 --- 요청 ---> 서버  
클라이언트 <--- 응답 --- 서버  
(매 리소스마다 반복)
```
<br>
🔹 Q2. HTTP/1.1의 keep-alive는 어떤 문제를 해결하나요?

- keep-alive는 TCP 연결을 한 번만 열고, 여러 요청을 같은 연결에서 처리합니다.
- 이를 통해 RTT 감소 및 연결 재사용으로 성능이 향상됩니다.
- 하지만 HOL(Head-of-Line) Blocking은 여전히 존재합니다.

💡 코드 기반 예시 (HTTP 헤더)

```http
Connection: keep-alive
```
<br>
🔹 Q3. HTTP/2에서 멀티플렉싱이란?

- 하나의 TCP 연결 내에서 여러 스트림을 병렬로 전송하는 기술입니다.
- 이 덕분에 하나의 요청 지연이 다른 요청에 영향을 주지 않아 HOL Blocking 문제를 해결합니다.

💡 그림 예시

```
[Stream 1] ===> ◯────────────>  
[Stream 2] ===> ◯─────>  
[Stream 3] ===> ◯───────────────>  
             (동일한 연결 내에서 병렬로 처리됨)
```


<br>
🔹 Q4. HTTP/3은 왜 UDP를 기반으로 하나요?

- TCP는 지연을 줄이기 위한 3-Way Handshake와 연결 유지 비용이 큽니다.
- HTTP/3은 QUIC(UDP 기반)를 사용하여 1-RTT 또는 0-RTT 연결이 가능하고, 
- TCP의 HOL Blocking 문제도 해결합니다.

💡 그림 예시 (TCP vs QUIC)

```
TCP: SYN → SYN-ACK → ACK → 시작 (3 RTT)  
QUIC: Initial Packet → Response → 시작 (1 RTT)
```

<br>

🔹 Q5. TLS 핸드셰이크 과정 설명해보세요.

- TLS 핸드셰이크는 클라이언트와 서버가 암호화 통신을 위한 키를 협상하고, 신뢰할 수 있는 인증서를 교환하는 과정입니다.

💡 과정 요약

1. 클라이언트: 지원 가능한 암호화 스펙 전달
2. 서버: 스펙 선택 + 인증서 전달
3. 클라이언트: 인증서 확인 + 키 공유
4. 암호화된 통신 시작

💡 코드 예시 (OpenSSL 서버 설정)

```bash
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365
```

<br>

🔹 Q6. 백엔드 개발자가 NAT 환경에서 주의해야 할 점은?

- NAT는 사설 IP를 공인 IP로 매핑하므로 클라이언트 IP가 동일하게 보이는 문제가 있습니다.
- 따라서 `X-Forwarded-For` 헤더를 통해 실제 클라이언트 IP를 추출해야 하며, WebSocket 등 연결 기반 서비스는 포트 포워딩 및 Keepalive 설정이 필요합니다.

💡 코드 예시 (Spring Boot)

```java
String clientIp = request.getHeader("X-Forwarded-For");
```

<br>

🔹 Q7. TLS는 어떻게 보안을 강화하나요?

- TLS는 암호화, 인증, 무결성을 보장합니다. 중간자 공격을 방지하며 클라이언트-서버 간 데이터가 도청되거나 위조되는 것을 막습니다.

💡 보안 구성 요소

* 인증서 (CA 발급, 공개키 포함)
* 암호화 (대칭키 방식)
* 무결성 확인 (HMAC 또는 SHA-256 해시)

<br>

🔹 Q8. HTTPS 구축 방법은?


1. 인증서를 CA에서 발급받거나 Let's Encrypt 등 무료 도구 사용
2. 인증서와 프라이빗 키를 웹 서버에 등록 (예: Nginx, Apache)
3. 443 포트를 개방하고 HTTPS 리다이렉트 설정

💡 Nginx 설정 예시

```nginx
server {
  listen 443 ssl;
  ssl_certificate /etc/nginx/ssl/cert.pem;
  ssl_certificate_key /etc/nginx/ssl/key.pem;
}
```

<br>

🔹 Q9. HTTP/3 도입 시 고려할 점은?


1. 서버와 클라이언트가 모두 HTTP/3과 QUIC을 지원해야 함
2. UDP 포트 (보통 443) 사용 → 방화벽 설정 필요
3. 기존 모니터링 툴이 UDP 기반을 지원하지 않을 수 있음

<br>

🔹 Q10. 백엔드 개발 관점에서 HTTPS가 SEO에 도움을 주는 이유는?

- Google은 HTTPS 웹사이트를 더 신뢰하고, 검색 순위에서 우대합니다.
- 또한 사용자 개인정보 보호 및 데이터 위조 방지로 UX도 개선됩니다.

💡 실제 예시

* Google PageSpeed Insights에서 HTTPS 도입 사이트가 속도 및 SEO 점수에서 더 좋은 평가를 받음
---

### ✅ HTTP/3의 보안 특성

1. **기본적으로 TLS 1.3 사용**

  * HTTP/1.1이나 HTTP/2는 TLS를 선택적으로 쓸 수 있었지만,
    **HTTP/3는 무조건 TLS 1.3을 사용합니다.**
  * 최신 보안 프로토콜인 TLS 1.3은 다음과 같은 강점을 가집니다:

    * **0-RTT 핸드셰이크**: 재접속 시 지연 줄이면서도 암호화 유지
    * **불필요한 알고리즘 제거**: 오래된, 취약한 암호화 방식 제거
    * **Forward secrecy**(전방향 보안성) 제공

2. **TCP가 아닌 UDP 기반의 QUIC 사용**

  * HTTP/3는 **QUIC 위에서 동작**하며, 이 QUIC 자체가 **암호화 통신 전용**입니다.
  * QUIC는 **TLS를 내장**하여, 패킷 수준에서도 항상 암호화된 데이터만 처리합니다.
  * 덕분에 중간자 공격(MITM), 세션 탈취, 헤더 조작 등을 **원천 차단**할 수 있습니다.

3. **헤더 조작 방지**

  * QUIC은 HTTP 헤더 자체도 암호화하여, 트래픽 분석이나 메타데이터 노출 위험을 줄입니다.

---

### 🔒 요약

| 항목        | HTTP/1.1 | HTTP/2            | HTTP/3            |
| --------- | -------- | ----------------- | ----------------- |
| TLS 필수 여부 | ❌ 선택     | ❌ 선택 (하지만 대부분 사용) | ✅ 필수 (TLS 1.3 내장) |
| 전송 프로토콜   | TCP      | TCP               | UDP (QUIC)        |
| 보안 수준     | 중        | 중\~상              | **상 (최신 보안 내장)**  |

---

### 💡 오해 방지

* "UDP 기반이라 덜 안전한 것 아닌가요?" → 일반적인 UDP는 비신뢰성 있지만, **QUIC은 보안 설계가 TCP보다 더 엄격**하게 이루어졌습니다.
* 즉, **HTTP/3는 속도와 보안 둘 다 잡은 프로토콜**입니다.

---

좋은 질문이에요. 결론부터 말하면:

> **요즘은 HTTP/3만 사용하는 건 아니고, HTTP/1.1 · HTTP/2 · HTTP/3가 '혼용'되고 있습니다.**
> 다만 **HTTP/3 채택률은 점점 늘어나고 있는 중**입니다.

---

### ✅ 현재 사용 현황 (2025년 기준)

| 프로토콜         | 특징             | 사용 비율 (대략)             | 비고             |
| ------------ | -------------- | ---------------------- | -------------- |
| **HTTP/1.1** | 가장 오래된, 기본     | 🌐 여전히 많이 사용됨          | 레거시 시스템, 일부 서버 |
| **HTTP/2**   | 속도 개선, 병렬 처리   | 🌐🌐 대부분 서버에서 기본       | 널리 채택된 버전      |
| **HTTP/3**   | 최신, 빠름 + 보안 강화 | 🌐 점점 증가 중 (~~30~~50%) | 최신 브라우저·CDN 중심 |

> 🔎 참고: Cloudflare, Google, Facebook 같은 글로벌 서비스들은 이미 HTTP/3 우선 적용 중입니다.
> Chrome, Edge, Safari, Firefox 등 주요 브라우저도 모두 지원합니다.

---

### 💡 왜 HTTP/3가 아직 100% 채택되지 않았을까?

1. **서버와 네트워크 장비 지원이 필요**

  * HTTP/3는 **UDP 기반**이기 때문에 방화벽, 라우터가 이를 제대로 처리해야 함
  * 기업 네트워크나 구형 서버는 아직 UDP 기반 QUIC을 막거나 미지원

2. **완벽한 backwards compatibility**

  * 대부분 브라우저와 서버는 HTTP/3를 **자동 협상**합니다
    → 즉, 클라이언트가 HTTP/3 지원하면 HTTP/3 사용
    → 아니면 HTTP/2 또는 1.1로 자동 fallback됨

3. **HTTP/3는 초기 연결 설정 시 더 빠르지만, 처리 비용이 더 클 수도 있음**

  * 가벼운 요청이나 단순 API 서비스에서는 HTTP/2가 더 효율적인 경우도 있음

---

### 👨‍💻 백엔드 개발자 관점 정리

* **HTTP/3 지원은 선택 아닌 필수로 가는 중**
  → CDN (Cloudflare, AWS CloudFront), Web Server (Nginx, Apache 등)에서도 HTTP/3 옵션 점점 기본화

* **fallback 고려 필수**
  → `Alt-Svc` 헤더를 통해 HTTP/3 사용 가능 안내하면서 HTTP/2/1.1도 함께 지원해야 사용자 경험 보장

* **QUIC, TLS 1.3, UDP 기반 통신의 이해가 중요**
  → 특히 실시간, 모바일, 게임, 동영상 스트리밍 서비스 백엔드에서 **HTTP/3는 매우 유리**

---

물론입니다. 아래는 HTTPS를 구축하는 대표적인 3가지 방법에 대한 상세한 설명입니다. 백엔드 개발자 관점에서 각각의 장단점과 쓰임새까지 함께 정리해드릴게요.

---

### ✅ 방법 1. 서버에 직접 인증서 설치 (인증기관에서 구매 또는 무료 발급)

**개요:**
서버에 직접 SSL 인증서를 설치해 HTTPS 통신을 가능하게 만드는 가장 기본적인 방법입니다.

**구성 흐름:**

1. 인증기관(CA, 예: Let's Encrypt, Sectigo, GlobalSign)에서 인증서 발급
2. 서버에 `.crt`, `.key` 파일 설치
3. 웹 서버 설정 (예: Nginx, Apache)에서 HTTPS 포트(443번)와 인증서 경로 지정
4. 포트 오픈 및 HTTP→HTTPS 리디렉션 설정

**예시 (Nginx):**

```nginx
server {
    listen 443 ssl;
    server_name yourdomain.com;

    ssl_certificate /etc/ssl/yourdomain.crt;
    ssl_certificate_key /etc/ssl/yourdomain.key;

    location / {
        proxy_pass http://localhost:8080;
    }
}
```

**장점:**

* 제어권이 100% 본인에게 있음
* 서버 보안 직접 설정 가능 (TLS 버전, 암호화 스위트 등)

**단점:**

* 직접 설치와 유지보수(갱신 자동화 등)가 필요
* 클러스터/멀티 인스턴스 환경에서 반복 작업 부담

---

### ✅ 방법 2. HTTPS를 지원하는 로드 밸런서를 앞단에 두기 (ex: AWS ELB, Nginx LB)

**개요:**
HTTPS 처리를 로드 밸런서가 대신 수행하고, 백엔드 서버는 HTTP로만 통신합니다. 즉, SSL 종료(termination)를 로드 밸런서에서 처리.

**구성 흐름:**

1. 로드 밸런서에 인증서 설치
2. 클라이언트 → 로드밸런서(HTTPS) → 백엔드 서버(HTTP)
3. 필요 시 `X-Forwarded-Proto`, `X-Forwarded-For` 헤더로 원 요청 정보 전달

**장점:**

* 백엔드 서버에서 SSL 처리 안 해도 됨 → 성능 향상
* 인증서 관리가 로드밸런서 쪽에서 통합 관리
* 고가용성 + 자동 스케일링 구성 쉬움

**단점:**

* LB에 의존적
* 클라이언트와 백엔드 간에 완전한 end-to-end 암호화가 아님 (중간 평문)

---

### ✅ 방법 3. CDN을 활용한 HTTPS 구축 (Cloudflare, AWS CloudFront, Naver CDN 등)

**개요:**
CDN이 클라이언트 요청을 받아 HTTPS 처리하고, 서버로는 HTTP or HTTPS로 전달하는 구조입니다.

**구성 흐름:**

1. CDN 제공 업체에 인증서 구성 (보통 자동 제공 or Bring Your Own Certificate 가능)
2. 도메인 설정 및 DNS 레코드 → CDN IP로 설정
3. CDN이 HTTPS 응답 담당 (속도 + 보안 강화)

**장점:**

* 성능 향상 (콘텐츠 캐싱, 전 세계 엣지서버)
* HTTPS 자동 구성 및 무료 SSL 지원 (ex: Cloudflare 무료 플랜도 있음)
* 봇/DoS 공격 방어, WAF, 브라우저 TLS 최신 버전 지원 등 부가기능 많음

**단점:**

* 모든 요청이 CDN을 경유하므로 디버깅이나 실시간 로그 수집이 불편할 수 있음
* CDN 미사용 리소스는 추가 설정 필요

---

### 📌 비교 요약

| 항목        | 서버 직접 설치     | 로드밸런서       | CDN             |
| --------- | ------------ | ----------- | --------------- |
| 인증서 설치 위치 | 서버           | LB          | CDN             |
| 복잡도       | 높음           | 중간          | 낮음              |
| 성능        | 낮음           | 중간\~좋음      | 매우 좋음           |
| 보안 통제력    | 가장 높음        | 중간          | 낮음 (CDN 업체에 위임) |
| 추천 환경     | 단일 서버, 자체 서버 | 다수 서버, 클라우드 | 트래픽 많고 글로벌 서비스  |
